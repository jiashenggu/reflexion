{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torchdata' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torchdata ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "from FlagEmbedding import FlagModel\n",
    "sentences_1 = [\"样例数据-1\", \"样例数据-2\"]\n",
    "sentences_2 = [\"样例数据-3\", \"样例数据-4\"]\n",
    "model = FlagModel('/ML-A100/home/gujiasheng/bge-small-en', \n",
    "                  query_instruction_for_retrieval=\"Represent this sentence for searching relevant passages: \",\n",
    "                  use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)\n",
    "\n",
    "# for s2p(short query to long passage) retrieval task, suggest to use encode_queries() which will automatically add the instruction to each query\n",
    "# corpus in retrieval task can still use encode() or encode_corpus(), since they don't need instruction\n",
    "queries = ['good']\n",
    "passages = [\"This is a good sentence\", \"This is a bad sentence\"]\n",
    "q_embeddings = model.encode_queries(queries)\n",
    "p_embeddings = model.encode(passages)\n",
    "scores = q_embeddings @ p_embeddings.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gujiasheng/miniconda3/envs/swe-bench/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "2023-11-24 13:44:35,167 WARNING Disabling caching\n",
      "/home/gujiasheng/miniconda3/envs/swe-bench/lib/python3.9/site-packages/ghapi/core.py:102: UserWarning: Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated\n",
      "  else: warn('Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b098f5b15f8a4d48b108a992043d9b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 13:44:45,531 INFO Creating instance pytorch__data-1169\n",
      "2023-11-24 13:44:45,532 INFO Cloning repo pytorch/data\n",
      "2023-11-24 13:44:45,558 INFO Buidling BM25 retrieval index for pytorch/data@a5b4720dece60565788ac4c9a85e01719188b28e\n",
      "2023-11-24 13:44:45,721 INFO Retrieved 3 documents\n",
      "2023-11-24 13:44:45,762 INFO Including 3 files in context with 3332 tokens:\n",
      "scripts/release_notes/commitlist.py____6\n",
      "\ttorchdata/dataloader2/communication/iter.py____10\n",
      "\ttorchdata/dataloader2/communication/map.py____5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchdata/dataloader2/communication/map.py____5\n",
      "scripts/release_notes/commitlist.py____6\n",
      "torchdata/dataloader2/communication/iter.py____10\n"
     ]
    }
   ],
   "source": [
    "from retrieve_source_code import retrieve_repo\n",
    "args = {\n",
    "    \"query\": \"good\",\n",
    "    \"prompt_style\": \"style-3\",\n",
    "    \"issue_url\": [\"https://github.com/pytorch/data/issues/1169\"],\n",
    "    \"base_commit\": [None],\n",
    "    \"max_context_length\": 4096,\n",
    "    \"document_encoding_func\": \"file_name_and_contents\",\n",
    "    \"root_dir\": \"./run_live_data\",\n",
    "    \"include_readmes\": False\n",
    "}\n",
    "\n",
    "instance = retrieve_repo(**args)\n",
    "retrieved_source_code = \"\"\n",
    "for v in instance['file_contents'].values():\n",
    "    retrieved_source_code += v + \"\\n\\n\\n\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retrieved_apis]:\n",
      "{retrieved_apis}\n",
      "\n",
      "[retrieved_functions]:\n",
      "{retrieved_functions}\n",
      "\n",
      "{func_sig}\n"
     ]
    }
   ],
   "source": [
    "print('[retrieved_apis]:\\n{retrieved_apis}\\n\\n[retrieved_source_code]:\\n{retrieved_source_code}\\n\\n{func_sig}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
